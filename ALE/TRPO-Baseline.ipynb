{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gym==0.25.2\n!pip install ale_py==0.7.5\n!pip install gym[atari]\n!pip install gym[accept-rom-license]\n!pip install autorom[accept-rom-license]\n\n! AutoROM --accept-license\n! \"ale-import-roms\" \"/opt/conda/lib/python3.10/site-packages/AutoROM/roms\"","metadata":{"execution":{"iopub.status.busy":"2023-06-01T19:12:40.202487Z","iopub.execute_input":"2023-06-01T19:12:40.202993Z","iopub.status.idle":"2023-06-01T19:14:08.049849Z","shell.execute_reply.started":"2023-06-01T19:12:40.202953Z","shell.execute_reply":"2023-06-01T19:14:08.048532Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gym==0.25.2\n  Downloading gym-0.25.2.tar.gz (734 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.5/734.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym==0.25.2) (1.23.5)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym==0.25.2) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym==0.25.2) (0.0.8)\nBuilding wheels for collected packages: gym\n  Building wheel for gym (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gym: filename=gym-0.25.2-py3-none-any.whl size=852303 sha256=7936ba87061e1534e959e62e8b63437a605b00d27fbf20a6f92ec34e82e7d5d1\n  Stored in directory: /root/.cache/pip/wheels/78/95/2c/ee47a8d43fda6a851e340e77e27cf75b49ff4ce2d1540c0e80\nSuccessfully built gym\nInstalling collected packages: gym\n  Attempting uninstall: gym\n    Found existing installation: gym 0.26.2\n    Uninstalling gym-0.26.2:\n      Successfully uninstalled gym-0.26.2\nSuccessfully installed gym-0.25.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting ale_py==0.7.5\n  Downloading ale_py-0.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from ale_py==0.7.5) (1.23.5)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale_py==0.7.5) (5.12.0)\nInstalling collected packages: ale_py\nSuccessfully installed ale_py-0.7.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: gym[atari] in /opt/conda/lib/python3.10/site-packages (0.25.2)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (1.23.5)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (0.0.8)\nRequirement already satisfied: ale-py~=0.7.5 in /opt/conda/lib/python3.10/site-packages (from gym[atari]) (0.7.5)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from ale-py~=0.7.5->gym[atari]) (5.12.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: gym[accept-rom-license] in /opt/conda/lib/python3.10/site-packages (0.25.2)\nRequirement already satisfied: numpy>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (1.23.5)\nRequirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (2.2.1)\nRequirement already satisfied: gym-notices>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from gym[accept-rom-license]) (0.0.8)\nCollecting autorom[accept-rom-license]~=0.4.2 (from gym[accept-rom-license])\n  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (8.1.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2.28.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (4.64.1)\nCollecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license])\n  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license]) (2023.5.7)\nBuilding wheels for collected packages: AutoROM.accept-rom-license\n  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446660 sha256=db0373d9bb13a302b78649535d34d50374caeee1e482dc6c7bfd8933d5158db8\n  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\nSuccessfully built AutoROM.accept-rom-license\nInstalling collected packages: AutoROM.accept-rom-license, autorom\nSuccessfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.4.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: autorom[accept-rom-license] in /opt/conda/lib/python3.10/site-packages (0.4.2)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]) (8.1.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]) (2.28.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]) (4.64.1)\nRequirement already satisfied: AutoROM.accept-rom-license in /opt/conda/lib/python3.10/site-packages (from autorom[accept-rom-license]) (0.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->autorom[accept-rom-license]) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mAutoROM will download the Atari 2600 ROMs.\nThey will be installed to:\n\t/opt/conda/lib/python3.10/site-packages/AutoROM/roms\n\nExisting ROMs will be overwritten.\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/adventure.bin    \nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/air_raid.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/alien.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/amidar.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/assault.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/asterix.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/asteroids.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/atlantis.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/atlantis2.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/backgammon.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/bank_heist.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/basic_math.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/battle_zone.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/beam_rider.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/berzerk.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/blackjack.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/bowling.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/boxing.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/breakout.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/carnival.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/casino.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/centipede.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/chopper_command.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/combat.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/crazy_climber.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/crossbow.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/darkchambers.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/defender.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/demon_attack.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/donkey_kong.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/double_dunk.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/earthworld.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/elevator_action.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/enduro.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/entombed.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/et.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/fishing_derby.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/flag_capture.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/freeway.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/frogger.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/frostbite.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/galaxian.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/gopher.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/gravitar.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/hangman.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/haunted_house.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/hero.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/human_cannonball.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/ice_hockey.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/jamesbond.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/journey_escape.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/joust.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/kaboom.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/kangaroo.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/keystone_kapers.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/king_kong.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/klax.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/koolaid.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/krull.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/kung_fu_master.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/laser_gates.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/lost_luggage.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/mario_bros.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/maze_craze.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/miniature_golf.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/montezuma_revenge.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/mr_do.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/ms_pacman.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/name_this_game.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/othello.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pacman.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/phoenix.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pitfall.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pitfall2.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pong.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pooyan.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/private_eye.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/qbert.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/riverraid.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/road_runner.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/robotank.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/seaquest.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/sir_lancelot.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/skiing.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/solaris.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/space_invaders.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/space_war.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/star_gunner.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/superman.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/surround.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/tennis.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/tetris.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/tic_tac_toe_3d.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/time_pilot.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/trondead.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/turmoil.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/tutankham.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/up_n_down.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/venture.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/video_checkers.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/video_chess.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/video_cube.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/video_pinball.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/warlords.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/wizard_of_wor.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/word_zapper.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/yars_revenge.bin\nInstalled /opt/conda/lib/python3.10/site-packages/AutoROM/roms/zaxxon.bin\nDone!\n\u001b[92m[SUPPORTED]    \u001b[0m             gravitar /opt/conda/lib/python3.10/site-packages/AutoROM/roms/gravitar.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             surround /opt/conda/lib/python3.10/site-packages/AutoROM/roms/surround.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             crossbow /opt/conda/lib/python3.10/site-packages/AutoROM/roms/crossbow.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              asterix /opt/conda/lib/python3.10/site-packages/AutoROM/roms/asterix.bin\n\u001b[92m[SUPPORTED]    \u001b[0m         demon_attack /opt/conda/lib/python3.10/site-packages/AutoROM/roms/demon_attack.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              freeway /opt/conda/lib/python3.10/site-packages/AutoROM/roms/freeway.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               kaboom /opt/conda/lib/python3.10/site-packages/AutoROM/roms/kaboom.bin\n\u001b[92m[SUPPORTED]    \u001b[0m                krull /opt/conda/lib/python3.10/site-packages/AutoROM/roms/krull.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              phoenix /opt/conda/lib/python3.10/site-packages/AutoROM/roms/phoenix.bin\n\u001b[92m[SUPPORTED]    \u001b[0m           earthworld /opt/conda/lib/python3.10/site-packages/AutoROM/roms/earthworld.bin\n\u001b[92m[SUPPORTED]    \u001b[0m    montezuma_revenge /opt/conda/lib/python3.10/site-packages/AutoROM/roms/montezuma_revenge.bin\n\u001b[92m[SUPPORTED]    \u001b[0m           backgammon /opt/conda/lib/python3.10/site-packages/AutoROM/roms/backgammon.bin\n\u001b[92m[SUPPORTED]    \u001b[0m      keystone_kapers /opt/conda/lib/python3.10/site-packages/AutoROM/roms/keystone_kapers.bin\n\u001b[92m[SUPPORTED]    \u001b[0m       name_this_game /opt/conda/lib/python3.10/site-packages/AutoROM/roms/name_this_game.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             kangaroo /opt/conda/lib/python3.10/site-packages/AutoROM/roms/kangaroo.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              berzerk /opt/conda/lib/python3.10/site-packages/AutoROM/roms/berzerk.bin\n\u001b[92m[SUPPORTED]    \u001b[0m                 pong /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pong.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              venture /opt/conda/lib/python3.10/site-packages/AutoROM/roms/venture.bin\n\u001b[92m[SUPPORTED]    \u001b[0m         lost_luggage /opt/conda/lib/python3.10/site-packages/AutoROM/roms/lost_luggage.bin\n\u001b[92m[SUPPORTED]    \u001b[0m           time_pilot /opt/conda/lib/python3.10/site-packages/AutoROM/roms/time_pilot.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            atlantis2 /opt/conda/lib/python3.10/site-packages/AutoROM/roms/atlantis2.bin\n\u001b[92m[SUPPORTED]    \u001b[0m           mario_bros /opt/conda/lib/python3.10/site-packages/AutoROM/roms/mario_bros.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             entombed /opt/conda/lib/python3.10/site-packages/AutoROM/roms/entombed.bin\n\u001b[92m[SUPPORTED]    \u001b[0m        video_pinball /opt/conda/lib/python3.10/site-packages/AutoROM/roms/video_pinball.bin\n\u001b[92m[SUPPORTED]    \u001b[0m          battle_zone /opt/conda/lib/python3.10/site-packages/AutoROM/roms/battle_zone.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            space_war /opt/conda/lib/python3.10/site-packages/AutoROM/roms/space_war.bin\n\u001b[92m[SUPPORTED]    \u001b[0m     human_cannonball /opt/conda/lib/python3.10/site-packages/AutoROM/roms/human_cannonball.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             defender /opt/conda/lib/python3.10/site-packages/AutoROM/roms/defender.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            videocube /opt/conda/lib/python3.10/site-packages/AutoROM/roms/video_cube.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              hangman /opt/conda/lib/python3.10/site-packages/AutoROM/roms/hangman.bin\n\u001b[92m[SUPPORTED]    \u001b[0m          double_dunk /opt/conda/lib/python3.10/site-packages/AutoROM/roms/double_dunk.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               pacman /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pacman.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            riverraid /opt/conda/lib/python3.10/site-packages/AutoROM/roms/riverraid.bin\n\u001b[92m[SUPPORTED]    \u001b[0m                qbert /opt/conda/lib/python3.10/site-packages/AutoROM/roms/qbert.bin\n\u001b[92m[SUPPORTED]    \u001b[0m       video_checkers /opt/conda/lib/python3.10/site-packages/AutoROM/roms/video_checkers.bin\n\u001b[92m[SUPPORTED]    \u001b[0m                 hero /opt/conda/lib/python3.10/site-packages/AutoROM/roms/hero.bin\n\u001b[92m[SUPPORTED]    \u001b[0m      chopper_command /opt/conda/lib/python3.10/site-packages/AutoROM/roms/chopper_command.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               boxing /opt/conda/lib/python3.10/site-packages/AutoROM/roms/boxing.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             air_raid /opt/conda/lib/python3.10/site-packages/AutoROM/roms/air_raid.bin\n\u001b[92m[SUPPORTED]    \u001b[0m          laser_gates /opt/conda/lib/python3.10/site-packages/AutoROM/roms/laser_gates.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              pitfall /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pitfall.bin\n\u001b[92m[SUPPORTED]    \u001b[0m       space_invaders /opt/conda/lib/python3.10/site-packages/AutoROM/roms/space_invaders.bin\n\u001b[92m[SUPPORTED]    \u001b[0m          road_runner /opt/conda/lib/python3.10/site-packages/AutoROM/roms/road_runner.bin\n\u001b[92m[SUPPORTED]    \u001b[0m          donkey_kong /opt/conda/lib/python3.10/site-packages/AutoROM/roms/donkey_kong.bin\n\u001b[92m[SUPPORTED]    \u001b[0m        wizard_of_wor /opt/conda/lib/python3.10/site-packages/AutoROM/roms/wizard_of_wor.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               enduro /opt/conda/lib/python3.10/site-packages/AutoROM/roms/enduro.bin\n\u001b[92m[SUPPORTED]    \u001b[0m         flag_capture /opt/conda/lib/python3.10/site-packages/AutoROM/roms/flag_capture.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             robotank /opt/conda/lib/python3.10/site-packages/AutoROM/roms/robotank.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            adventure /opt/conda/lib/python3.10/site-packages/AutoROM/roms/adventure.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             galaxian /opt/conda/lib/python3.10/site-packages/AutoROM/roms/galaxian.bin\n\u001b[92m[SUPPORTED]    \u001b[0m                   et /opt/conda/lib/python3.10/site-packages/AutoROM/roms/et.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              solaris /opt/conda/lib/python3.10/site-packages/AutoROM/roms/solaris.bin\n\u001b[92m[SUPPORTED]    \u001b[0m                mr_do /opt/conda/lib/python3.10/site-packages/AutoROM/roms/mr_do.bin\n\u001b[92m[SUPPORTED]    \u001b[0m                alien /opt/conda/lib/python3.10/site-packages/AutoROM/roms/alien.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               gopher /opt/conda/lib/python3.10/site-packages/AutoROM/roms/gopher.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               casino /opt/conda/lib/python3.10/site-packages/AutoROM/roms/casino.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               zaxxon /opt/conda/lib/python3.10/site-packages/AutoROM/roms/zaxxon.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               skiing /opt/conda/lib/python3.10/site-packages/AutoROM/roms/skiing.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              othello /opt/conda/lib/python3.10/site-packages/AutoROM/roms/othello.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             trondead /opt/conda/lib/python3.10/site-packages/AutoROM/roms/trondead.bin\n\u001b[92m[SUPPORTED]    \u001b[0m       journey_escape /opt/conda/lib/python3.10/site-packages/AutoROM/roms/journey_escape.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              turmoil /opt/conda/lib/python3.10/site-packages/AutoROM/roms/turmoil.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            king_kong /opt/conda/lib/python3.10/site-packages/AutoROM/roms/king_kong.bin\n\u001b[92m[SUPPORTED]    \u001b[0m       miniature_golf /opt/conda/lib/python3.10/site-packages/AutoROM/roms/miniature_golf.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              assault /opt/conda/lib/python3.10/site-packages/AutoROM/roms/assault.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             breakout /opt/conda/lib/python3.10/site-packages/AutoROM/roms/breakout.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            blackjack /opt/conda/lib/python3.10/site-packages/AutoROM/roms/blackjack.bin\n\u001b[92m[SUPPORTED]    \u001b[0m         sir_lancelot /opt/conda/lib/python3.10/site-packages/AutoROM/roms/sir_lancelot.bin\n\u001b[92m[SUPPORTED]    \u001b[0m         yars_revenge /opt/conda/lib/python3.10/site-packages/AutoROM/roms/yars_revenge.bin\n\u001b[92m[SUPPORTED]    \u001b[0m        fishing_derby /opt/conda/lib/python3.10/site-packages/AutoROM/roms/fishing_derby.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            centipede /opt/conda/lib/python3.10/site-packages/AutoROM/roms/centipede.bin\n\u001b[92m[SUPPORTED]    \u001b[0m          star_gunner /opt/conda/lib/python3.10/site-packages/AutoROM/roms/star_gunner.bin\n\u001b[92m[SUPPORTED]    \u001b[0m        crazy_climber /opt/conda/lib/python3.10/site-packages/AutoROM/roms/crazy_climber.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            frostbite /opt/conda/lib/python3.10/site-packages/AutoROM/roms/frostbite.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             seaquest /opt/conda/lib/python3.10/site-packages/AutoROM/roms/seaquest.bin\n\u001b[92m[SUPPORTED]    \u001b[0m          word_zapper /opt/conda/lib/python3.10/site-packages/AutoROM/roms/word_zapper.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               tennis /opt/conda/lib/python3.10/site-packages/AutoROM/roms/tennis.bin\n\u001b[92m[SUPPORTED]    \u001b[0m      elevator_action /opt/conda/lib/python3.10/site-packages/AutoROM/roms/elevator_action.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            ms_pacman /opt/conda/lib/python3.10/site-packages/AutoROM/roms/ms_pacman.bin\n\u001b[92m[SUPPORTED]    \u001b[0m        haunted_house /opt/conda/lib/python3.10/site-packages/AutoROM/roms/haunted_house.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               pooyan /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pooyan.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               amidar /opt/conda/lib/python3.10/site-packages/AutoROM/roms/amidar.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             superman /opt/conda/lib/python3.10/site-packages/AutoROM/roms/superman.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            asteroids /opt/conda/lib/python3.10/site-packages/AutoROM/roms/asteroids.bin\n\u001b[92m[SUPPORTED]    \u001b[0m         darkchambers /opt/conda/lib/python3.10/site-packages/AutoROM/roms/darkchambers.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            jamesbond /opt/conda/lib/python3.10/site-packages/AutoROM/roms/jamesbond.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              frogger /opt/conda/lib/python3.10/site-packages/AutoROM/roms/frogger.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            up_n_down /opt/conda/lib/python3.10/site-packages/AutoROM/roms/up_n_down.bin\n\u001b[92m[SUPPORTED]    \u001b[0m           ice_hockey /opt/conda/lib/python3.10/site-packages/AutoROM/roms/ice_hockey.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              koolaid /opt/conda/lib/python3.10/site-packages/AutoROM/roms/koolaid.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             atlantis /opt/conda/lib/python3.10/site-packages/AutoROM/roms/atlantis.bin\n\u001b[92m[SUPPORTED]    \u001b[0m               tetris /opt/conda/lib/python3.10/site-packages/AutoROM/roms/tetris.bin\n\u001b[92m[SUPPORTED]    \u001b[0m       kung_fu_master /opt/conda/lib/python3.10/site-packages/AutoROM/roms/kung_fu_master.bin\n\u001b[92m[SUPPORTED]    \u001b[0m          private_eye /opt/conda/lib/python3.10/site-packages/AutoROM/roms/private_eye.bin\n\u001b[92m[SUPPORTED]    \u001b[0m           videochess /opt/conda/lib/python3.10/site-packages/AutoROM/roms/video_chess.bin\n\u001b[92m[SUPPORTED]    \u001b[0m            tutankham /opt/conda/lib/python3.10/site-packages/AutoROM/roms/tutankham.bin\n\u001b[92m[SUPPORTED]    \u001b[0m           bank_heist /opt/conda/lib/python3.10/site-packages/AutoROM/roms/bank_heist.bin\n\u001b[92m[SUPPORTED]    \u001b[0m           basic_math /opt/conda/lib/python3.10/site-packages/AutoROM/roms/basic_math.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             carnival /opt/conda/lib/python3.10/site-packages/AutoROM/roms/carnival.bin\n\u001b[92m[SUPPORTED]    \u001b[0m              bowling /opt/conda/lib/python3.10/site-packages/AutoROM/roms/bowling.bin\n\u001b[92m[SUPPORTED]    \u001b[0m           beam_rider /opt/conda/lib/python3.10/site-packages/AutoROM/roms/beam_rider.bin\n\u001b[92m[SUPPORTED]    \u001b[0m                 klax /opt/conda/lib/python3.10/site-packages/AutoROM/roms/klax.bin\n\u001b[92m[SUPPORTED]    \u001b[0m       tic_tac_toe_3d /opt/conda/lib/python3.10/site-packages/AutoROM/roms/tic_tac_toe_3d.bin\n\u001b[92m[SUPPORTED]    \u001b[0m             pitfall2 /opt/conda/lib/python3.10/site-packages/AutoROM/roms/pitfall2.bin\n\n\n\u001b[91m[NOT SUPPORTED]\u001b[0m                      /opt/conda/lib/python3.10/site-packages/AutoROM/roms/combat.bin\n\u001b[91m[NOT SUPPORTED]\u001b[0m                      /opt/conda/lib/python3.10/site-packages/AutoROM/roms/joust.bin\n\u001b[91m[NOT SUPPORTED]\u001b[0m                      /opt/conda/lib/python3.10/site-packages/AutoROM/roms/maze_craze.bin\n\u001b[91m[NOT SUPPORTED]\u001b[0m                      /opt/conda/lib/python3.10/site-packages/AutoROM/roms/warlords.bin\n\nImported 104 / 108 ROMs\n","output_type":"stream"}]},{"cell_type":"code","source":"from ale_py import ALEInterface\n\nale = ALEInterface()\nale.loadROM('/opt/conda/lib/python3.10/site-packages/AutoROM/roms/freeway.bin')\nale.loadROM('/opt/conda/lib/python3.10/site-packages/AutoROM/roms/frostbite.bin')\nale.loadROM('/opt/conda/lib/python3.10/site-packages/AutoROM/roms/gravitar.bin')\nale.loadROM('/opt/conda/lib/python3.10/site-packages/AutoROM/roms/montezuma_revenge.bin')\nale.loadROM('/opt/conda/lib/python3.10/site-packages/AutoROM/roms/solaris.bin')\nale.loadROM('/opt/conda/lib/python3.10/site-packages/AutoROM/roms/venture.bin')","metadata":{"execution":{"iopub.status.busy":"2023-06-01T19:14:08.052963Z","iopub.execute_input":"2023-06-01T19:14:08.053816Z","iopub.status.idle":"2023-06-01T19:14:09.036185Z","shell.execute_reply.started":"2023-06-01T19:14:08.053774Z","shell.execute_reply":"2023-06-01T19:14:09.035223Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n[Powered by Stella]\nGame console created:\n  ROM file:  /opt/conda/lib/python3.10/site-packages/AutoROM/roms/freeway.bin\n  Cart Name: Freeway (1981) (Activision) [!]\n  Cart MD5:  8e0ab801b1705a740b476b7f588c6d16\n  Display Format:  AUTO-DETECT ==> NTSC\n  ROM Size:        2048\n  Bankswitch Type: AUTO-DETECT ==> 2K\n\nRunning ROM file...\nRandom seed is 1685646848\nGame console created:\n  ROM file:  /opt/conda/lib/python3.10/site-packages/AutoROM/roms/frostbite.bin\n  Cart Name: Frostbite (1983) (Activision)\n  Cart MD5:  4ca73eb959299471788f0b685c3ba0b5\n  Display Format:  AUTO-DETECT ==> NTSC\n  ROM Size:        4096\n  Bankswitch Type: AUTO-DETECT ==> 4K\n\nRunning ROM file...\nRandom seed is 1685646848\nGame console created:\n  ROM file:  /opt/conda/lib/python3.10/site-packages/AutoROM/roms/gravitar.bin\n  Cart Name: Gravitar (1988) (Atari) [a1][!]\n  Cart MD5:  8ac18076d01a6b63acf6e2cab4968940\n  Display Format:  AUTO-DETECT ==> NTSC\n  ROM Size:        8192\n  Bankswitch Type: AUTO-DETECT ==> F8\n\nRunning ROM file...\nRandom seed is 1685646848\nGame console created:\n  ROM file:  /opt/conda/lib/python3.10/site-packages/AutoROM/roms/montezuma_revenge.bin\n  Cart Name: Montezuma's Revenge - Starring Panama Joe (1983) (Parker Bros)\n  Cart MD5:  3347a6dd59049b15a38394aa2dafa585\n  Display Format:  AUTO-DETECT ==> NTSC\n  ROM Size:        8192\n  Bankswitch Type: AUTO-DETECT ==> E0\n\nRunning ROM file...\nRandom seed is 1685646848\nGame console created:\n  ROM file:  /opt/conda/lib/python3.10/site-packages/AutoROM/roms/solaris.bin\n  Cart Name: Solaris (1986) (Atari)\n  Cart MD5:  e72eb8d4410152bdcb69e7fba327b420\n  Display Format:  AUTO-DETECT ==> NTSC\n  ROM Size:        16384\n  Bankswitch Type: AUTO-DETECT ==> F6\n\nRunning ROM file...\nRandom seed is 1685646848\nGame console created:\n  ROM file:  /opt/conda/lib/python3.10/site-packages/AutoROM/roms/venture.bin\n  Cart Name: Venture (1982) (Coleco) [!]\n  Cart MD5:  3e899eba0ca8cd2972da1ae5479b4f0d\n  Display Format:  AUTO-DETECT ==> NTSC\n  ROM Size:        4096\n  Bankswitch Type: AUTO-DETECT ==> 4K\n\nRunning ROM file...\nRandom seed is 1685646849\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.distributions import Categorical\n\nfrom skimage.color import rgb2gray\nfrom skimage.transform import resize\nfrom collections import namedtuple\nfrom datetime import datetime\nimport numpy as np\nimport pathlib\nimport gym\n\nalgo = 'atari_baseline'\nTransition = namedtuple('Transition', ('state', 'action', 'reward'))\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n\ndef preprocess_image(img):\n    img = rgb2gray(img)\n    img = resize(img, (52, 52))\n    img = img * 2 - 1\n    return img\n\n\nclass Actor(nn.Module):\n    def __init__(self, num_outputs):\n        super(Actor, self).__init__()\n\n        self.layer1 = nn.Conv2d(4, 16, 8, stride=4, padding=3)\n        self.layer2 = nn.Conv2d(16, 32, 4, stride=2, padding=1)\n        self.layer3 = nn.Linear(6 * 6 * 32, 256)\n        self.layer4 = nn.Linear(256, num_outputs)\n\n        self.batch_norm1 = nn.BatchNorm2d(16)\n        self.batch_norm2 = nn.BatchNorm2d(32)\n        self.flatten = nn.Flatten()\n\n    def forward(self, inputs):\n        inputs = inputs.to(device)\n\n        x = self.layer1(inputs)\n        x = self.batch_norm1(F.relu(x))\n        x = self.layer2(x)\n        x = self.batch_norm2(F.relu(x))\n        x = self.flatten(x)\n\n        x = self.layer3(x)\n        x = F.relu(x)\n        x = F.softmax(self.layer4(x), dim=1)\n        return x.to('cpu')\n\n\nclass Critic(nn.Module):\n    def __init__(self):\n        super(Critic, self).__init__()\n\n        self.layer1 = nn.Conv2d(4, 16, 8, stride=4, padding=3)\n        self.layer2 = nn.Conv2d(16, 32, 4, stride=2, padding=1)\n        self.layer3 = nn.Linear(6 * 6 * 32, 256)\n        self.layer4 = nn.Linear(256, 1)\n\n        self.batch_norm1 = nn.BatchNorm2d(16)\n        self.batch_norm2 = nn.BatchNorm2d(32)\n        self.flatten = nn.Flatten()\n\n    def forward(self, inputs):\n        inputs = inputs.to(device)\n\n        x = self.layer1(inputs)\n        x = self.batch_norm1(F.relu(x))\n        x = self.layer2(x)\n        x = self.batch_norm2(F.relu(x))\n        x = self.flatten(x)\n\n        x = self.layer3(x)\n        x = F.relu(x)\n        x = self.layer4(x)\n        return x.to('cpu')\n\n\nclass TRPO(object):\n    def __init__(self, env, env_eval, gamma=0.995, lr_c=1e-3, save_folder=None):\n        self.env = env\n        self.env_eval = env_eval\n        self.num_states = env.observation_space.shape[0]\n        self.num_actions = env.action_space.n\n\n        self.actor = Actor(num_outputs=self.num_actions)\n        self.critic = Critic()\n        self.actor.to(device)\n        self.critic.to(device)\n\n        self.critic_loss_func = nn.MSELoss()\n        self.critic_optimizer = Adam(self.critic.parameters(), lr=lr_c)\n        self.gamma = gamma\n        self.memory = []\n\n        if save_folder is None:\n            name = self.env.unwrapped.spec.id.split('/')[-1].split('-')[0]\n            self.save_folder = f'pretrain/{algo}/' + name\n        else:\n            self.save_folder = save_folder\n        pathlib.Path(self.save_folder).mkdir(parents=True, exist_ok=True)\n        self.actor_path = self.save_folder + '/actor'\n        self.critic_path = self.save_folder + '/critic'\n\n    def select_action(self, state):\n        with torch.no_grad():\n            state = torch.tensor(state).float().unsqueeze(0)\n            dist = Categorical(self.actor(state))\n            return dist.sample().item()\n\n    def update_agent(self, update_step, delta=0.01, backtrack_ratio=0.8, max_backtracks=15, damping=1e-1):\n        states = torch.cat([tr.state for tr in self.memory], dim=0).float()\n        actions = torch.cat([tr.action for tr in self.memory], dim=0).flatten()\n\n        returns = []\n        for tr in self.memory:\n            R = 0\n            tr_returns = []\n            rewards = tr.reward\n            for reward in rewards[::-1]:\n                R = reward + self.gamma * R\n                tr_returns.append(R)\n            tr_returns = torch.as_tensor(tr_returns[::-1]).unsqueeze(1)\n            returns.append(tr_returns)\n        returns = torch.cat(returns, dim=0).float()\n        returns = (returns - returns.mean()) / (returns.std() + 1e-8)\n\n        idx = np.arange(returns.numpy().shape[0])\n        np.random.shuffle(idx)\n        idx = idx[:update_step]\n        states = torch.from_numpy(states.numpy()[idx])\n        actions = torch.from_numpy(actions.numpy()[idx])\n        returns = torch.from_numpy(returns.numpy()[idx])\n\n        baselines = self.critic(states)\n        self.critic_optimizer.zero_grad()\n        value_loss = self.critic_loss_func(baselines, returns)\n        value_loss.backward()\n        self.critic_optimizer.step()\n        with torch.no_grad():\n            baselines = self.critic(states)\n\n        dist = self.actor(states)\n        prob = dist[range(dist.shape[0]), actions].clamp(min=1e-38, max=1.)\n        const_dist = dist.detach().clone()\n        const_prob = prob.detach().clone()\n\n        parameters = list(self.actor.parameters())\n        advantages = (returns - baselines).detach().flatten()\n        # advantages = advantages / (advantages.std() + 1e-8)\n\n        L = ((prob / const_prob) * advantages).mean()\n        dL = torch.autograd.grad(L, parameters, retain_graph=True)\n        loss_grad = torch.cat([grad.flatten() for grad in dL])\n\n        def Fvp(v):\n            kl = self.get_kl(const_dist, dist).mean()\n            grads = torch.autograd.grad(kl, parameters, create_graph=True, retain_graph=True)\n            flat_grad_kl = torch.cat([grad.flatten() for grad in grads])\n            v_v = v.detach().clone().to(device)\n            kl_v = (flat_grad_kl * v_v).sum()\n            grads = torch.autograd.grad(kl_v, parameters, retain_graph=True)\n            flat_grad_grad_kl = torch.cat([grad.flatten() for grad in grads]).data\n            return flat_grad_grad_kl + v * damping\n\n        stepdir = self.conjugate_gradient(Fvp, loss_grad, 10)\n        shs = stepdir @ Fvp(stepdir)\n        max_length = torch.sqrt(2 * delta / shs) if shs != 0.0 else 0\n        max_step = (max_length * stepdir).to('cpu')\n\n        free_mem = L.flatten().sum()\n        torch.autograd.grad(free_mem, parameters, retain_graph=False)\n\n        def criterion(step):\n            self.update_actor(step)\n            with torch.no_grad():\n                dist_new = self.actor(states)\n                prob_new = dist_new[range(dist_new.shape[0]), actions]\n                L_new = ((prob_new / const_prob) * advantages).mean()\n                KL_new = self.get_kl(const_dist, dist_new).mean()\n                if L_new - L > 0 and KL_new <= delta:\n                    return True\n            self.update_actor(-step)\n            return False\n\n        i = 0\n        while not criterion((backtrack_ratio ** i) * max_step) and i < max_backtracks:\n            i += 1\n\n    def update_actor(self, grad_flattened):\n        n = 0\n        for params in self.actor.parameters():\n            num_element = params.numel()\n            g = grad_flattened[n:n + num_element].view(params.shape).to(device)\n            params.data += g\n            n += num_element\n\n    def conjugate_gradient(self, Avp, b, nsteps, residual_tol=1e-10):\n        x = torch.zeros(b.size()).to(device)\n        r = b.clone()\n        p = b.clone()\n        rdotr = torch.dot(r, r)\n        for i in range(nsteps):\n            if rdotr < residual_tol:\n                break\n            _Avp = Avp(p)\n            php = torch.dot(p, _Avp)\n            if php == 0.0:\n                break\n            alpha = rdotr / php\n            x += alpha * p\n            r -= alpha * _Avp\n            new_rdotr = torch.dot(r, r)\n            beta = new_rdotr / rdotr\n            p = r + beta * p\n            rdotr = new_rdotr\n        return x\n\n    def get_kl(self, p, q):\n        p_log = p.clamp(min=1e-38, max=1.).log()\n        q_log = q.clamp(min=1e-38, max=1.).log()\n        return (p * (p_log - q_log)).sum(-1)\n\n    def save_model(self):\n        torch.save(self.actor.state_dict(), self.actor_path)\n        torch.save(self.critic.state_dict(), self.critic_path)\n\n    def train(self, num_epoch=500, update_step=10000, show_freq=None):\n        i_episode = 0\n        best_reward = None\n        all_epoch_rewards = []\n        for i in range(num_epoch):\n            if show_freq is not None and i % show_freq == 0:\n                self.eval(num_episode=1)\n            self.actor.train()\n            self.critic.train()\n            print('Epoch {}/{}'.format(i + 1, num_epoch))\n            start_time = float(datetime.now().timestamp())\n            epoch_rewards = []\n\n            epoch_t = 0\n            while True:  # episodes loop\n                prev_states = list()\n                state = self.env.reset()\n                episode_reward = 0\n                sample = []\n\n                preprocess_state = preprocess_image(state)\n                prev_states.append(preprocess_state)\n                prev_states.append(preprocess_state)\n                prev_states.append(preprocess_state)\n                prev_states.append(preprocess_state)\n\n                t = 0\n                while True:\n                    input_stack = np.array(prev_states[-4:])\n                    action = self.select_action(input_stack)\n                    next_state, reward, done, _ = self.env.step(action)\n                    sample.append((input_stack, action, reward))\n                    prev_states.append(preprocess_image(next_state))\n                    episode_reward += reward\n                    epoch_t += 1\n                    t += 1\n                    if done:\n                        break\n\n                states, actions, rewards = zip(*sample)\n                states = torch.stack([torch.from_numpy(state) for state in states], dim=0).float()\n                actions = torch.as_tensor(actions).unsqueeze(1)\n                rewards = np.array(rewards)\n\n                self.memory.append(Transition(states, actions, rewards))\n                epoch_rewards.append(episode_reward)\n                sample.clear()\n\n                i_episode += 1\n                complete_ratio = min(epoch_t, update_step) * 19 // update_step\n                str1, str2 = '=' * complete_ratio, '-' * (19 - complete_ratio)\n                print('\\r{}/{} [{}>{}] '.format(min(epoch_t, update_step), update_step, str1, str2), end='')\n                if epoch_t >= update_step:\n                    break\n\n            epoch_avg_reward = sum(epoch_rewards) / len(epoch_rewards)\n            all_epoch_rewards.append(epoch_avg_reward)\n            if i/num_epoch > 0.9 and (best_reward is None or epoch_avg_reward > best_reward):\n                best_reward = epoch_avg_reward\n                self.save_model()\n\n            self.update_agent(update_step=update_step)\n            end_time = float(datetime.now().timestamp())\n            running_time = end_time - start_time\n            print('\\r{}/{} [====================] '.format(update_step, update_step), end='')\n            print('- {:.2f}s {:.2f}ms/step '.format(running_time, running_time * 1000 / epoch_t, 2), end='')\n            print('- num_episode: {} - avg_reward: {:.2f}'.format(len(epoch_rewards), epoch_avg_reward))\n            print('Peak cuda memory used: {:.2f}MB'.format(int(torch.cuda.max_memory_allocated()) / 1048576), end='\\n\\n')\n\n            torch.cuda.reset_max_memory_allocated(device=device)\n            epoch_rewards.clear()\n            self.memory.clear()\n            \n        return all_epoch_rewards\n\n    def eval(self, num_episode):\n        self.actor.eval()\n        self.critic.eval()\n        with torch.no_grad():\n            for i in range(num_episode):\n                prev_states = list()\n                state = self.env_eval.reset()\n                preprocess_state = preprocess_image(state)\n                prev_states.append(preprocess_state)\n                prev_states.append(preprocess_state)\n                prev_states.append(preprocess_state)\n                prev_states.append(preprocess_state)\n\n                t = 0\n                while True:\n                    input_stack = np.array(prev_states[-4:])\n                    action = self.select_action(input_stack)\n                    next_state, reward, done, _ = self.env_eval.step(action)\n                    prev_states.append(preprocess_image(next_state))\n                    t += 1\n                    if done or t > 10000:\n                        break","metadata":{"execution":{"iopub.status.busy":"2023-06-01T19:14:09.037830Z","iopub.execute_input":"2023-06-01T19:14:09.038404Z","iopub.status.idle":"2023-06-01T19:14:13.308973Z","shell.execute_reply.started":"2023-06-01T19:14:09.038370Z","shell.execute_reply":"2023-06-01T19:14:13.308012Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"random_seed = 48763\nenv_name = 'ALE/Freeway-v5'\ntrain_env = gym.make(env_name)\ntest_env = gym.make(env_name)\n\ntrain_env.seed(random_seed)\nnp.random.seed(random_seed)\ntorch.manual_seed(random_seed)\n\nagent = TRPO(train_env, test_env, gamma=0.995, lr_c=3e-4)\nall_epoch_rewards = agent.train(num_epoch=50, update_step=10000, show_freq=None)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T19:14:13.312291Z","iopub.execute_input":"2023-06-01T19:14:13.312954Z","iopub.status.idle":"2023-06-01T19:49:11.012626Z","shell.execute_reply.started":"2023-06-01T19:14:13.312928Z","shell.execute_reply":"2023-06-01T19:49:11.011614Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n[Powered by Stella]\n/opt/conda/lib/python3.10/site-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n  deprecation(\n/opt/conda/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n  deprecation(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n  logger.deprecation(\n","output_type":"stream"},{"name":"stdout","text":"10000/10000 [====================] - 49.83s 4.86ms/step - num_episode: 5 - avg_reward: 0.40\nPeak cuda memory used: 2264.04MB\n\nEpoch 2/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"10000/10000 [====================] - 41.44s 4.04ms/step - num_episode: 5 - avg_reward: 1.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 3/50\n10000/10000 [====================] - 42.27s 4.13ms/step - num_episode: 5 - avg_reward: 4.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 4/50\n10000/10000 [====================] - 41.58s 4.06ms/step - num_episode: 5 - avg_reward: 4.60\nPeak cuda memory used: 2263.87MB\n\nEpoch 5/50\n10000/10000 [====================] - 41.63s 4.06ms/step - num_episode: 5 - avg_reward: 4.80\nPeak cuda memory used: 2263.87MB\n\nEpoch 6/50\n10000/10000 [====================] - 41.62s 4.06ms/step - num_episode: 5 - avg_reward: 3.20\nPeak cuda memory used: 2263.87MB\n\nEpoch 7/50\n10000/10000 [====================] - 41.54s 4.06ms/step - num_episode: 5 - avg_reward: 3.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 8/50\n10000/10000 [====================] - 42.21s 4.12ms/step - num_episode: 5 - avg_reward: 4.60\nPeak cuda memory used: 2263.87MB\n\nEpoch 9/50\n10000/10000 [====================] - 41.73s 4.07ms/step - num_episode: 5 - avg_reward: 5.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 10/50\n10000/10000 [====================] - 43.54s 4.25ms/step - num_episode: 5 - avg_reward: 4.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 11/50\n10000/10000 [====================] - 42.35s 4.13ms/step - num_episode: 5 - avg_reward: 5.60\nPeak cuda memory used: 2263.87MB\n\nEpoch 12/50\n10000/10000 [====================] - 40.82s 3.98ms/step - num_episode: 5 - avg_reward: 5.20\nPeak cuda memory used: 2263.87MB\n\nEpoch 13/50\n10000/10000 [====================] - 41.50s 4.05ms/step - num_episode: 5 - avg_reward: 4.60\nPeak cuda memory used: 2263.87MB\n\nEpoch 14/50\n10000/10000 [====================] - 40.98s 4.00ms/step - num_episode: 5 - avg_reward: 6.20\nPeak cuda memory used: 2263.87MB\n\nEpoch 15/50\n10000/10000 [====================] - 40.89s 3.99ms/step - num_episode: 5 - avg_reward: 6.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 16/50\n10000/10000 [====================] - 41.04s 4.01ms/step - num_episode: 5 - avg_reward: 5.80\nPeak cuda memory used: 2263.87MB\n\nEpoch 17/50\n10000/10000 [====================] - 41.07s 4.01ms/step - num_episode: 5 - avg_reward: 8.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 18/50\n10000/10000 [====================] - 40.61s 3.96ms/step - num_episode: 5 - avg_reward: 7.20\nPeak cuda memory used: 2263.87MB\n\nEpoch 19/50\n10000/10000 [====================] - 40.68s 3.97ms/step - num_episode: 5 - avg_reward: 7.20\nPeak cuda memory used: 2263.87MB\n\nEpoch 20/50\n10000/10000 [====================] - 41.23s 4.02ms/step - num_episode: 5 - avg_reward: 7.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 21/50\n10000/10000 [====================] - 40.62s 3.97ms/step - num_episode: 5 - avg_reward: 8.80\nPeak cuda memory used: 2263.87MB\n\nEpoch 22/50\n10000/10000 [====================] - 40.81s 3.98ms/step - num_episode: 5 - avg_reward: 7.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 23/50\n10000/10000 [====================] - 41.25s 4.03ms/step - num_episode: 5 - avg_reward: 5.80\nPeak cuda memory used: 2263.87MB\n\nEpoch 24/50\n10000/10000 [====================] - 41.09s 4.01ms/step - num_episode: 5 - avg_reward: 5.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 25/50\n10000/10000 [====================] - 41.19s 4.02ms/step - num_episode: 5 - avg_reward: 4.80\nPeak cuda memory used: 2263.87MB\n\nEpoch 26/50\n10000/10000 [====================] - 41.80s 4.08ms/step - num_episode: 5 - avg_reward: 4.60\nPeak cuda memory used: 2263.87MB\n\nEpoch 27/50\n10000/10000 [====================] - 42.11s 4.11ms/step - num_episode: 5 - avg_reward: 5.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 28/50\n10000/10000 [====================] - 41.76s 4.08ms/step - num_episode: 5 - avg_reward: 5.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 29/50\n10000/10000 [====================] - 42.08s 4.11ms/step - num_episode: 5 - avg_reward: 6.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 30/50\n10000/10000 [====================] - 42.35s 4.13ms/step - num_episode: 5 - avg_reward: 6.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 31/50\n10000/10000 [====================] - 41.65s 4.07ms/step - num_episode: 5 - avg_reward: 5.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 32/50\n10000/10000 [====================] - 41.73s 4.07ms/step - num_episode: 5 - avg_reward: 5.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 33/50\n10000/10000 [====================] - 42.01s 4.10ms/step - num_episode: 5 - avg_reward: 5.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 34/50\n10000/10000 [====================] - 41.92s 4.09ms/step - num_episode: 5 - avg_reward: 7.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 35/50\n10000/10000 [====================] - 41.40s 4.04ms/step - num_episode: 5 - avg_reward: 7.80\nPeak cuda memory used: 2263.87MB\n\nEpoch 36/50\n10000/10000 [====================] - 41.68s 4.07ms/step - num_episode: 5 - avg_reward: 8.20\nPeak cuda memory used: 2263.87MB\n\nEpoch 37/50\n10000/10000 [====================] - 41.47s 4.05ms/step - num_episode: 5 - avg_reward: 9.20\nPeak cuda memory used: 2263.87MB\n\nEpoch 38/50\n10000/10000 [====================] - 42.03s 4.10ms/step - num_episode: 5 - avg_reward: 10.20\nPeak cuda memory used: 2263.87MB\n\nEpoch 39/50\n10000/10000 [====================] - 41.58s 4.06ms/step - num_episode: 5 - avg_reward: 11.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 40/50\n10000/10000 [====================] - 42.04s 4.10ms/step - num_episode: 5 - avg_reward: 10.20\nPeak cuda memory used: 2263.87MB\n\nEpoch 41/50\n10000/10000 [====================] - 41.42s 4.04ms/step - num_episode: 5 - avg_reward: 9.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 42/50\n10000/10000 [====================] - 41.50s 4.05ms/step - num_episode: 5 - avg_reward: 10.80\nPeak cuda memory used: 2263.87MB\n\nEpoch 43/50\n10000/10000 [====================] - 42.00s 4.10ms/step - num_episode: 5 - avg_reward: 9.80\nPeak cuda memory used: 2263.87MB\n\nEpoch 44/50\n10000/10000 [====================] - 42.25s 4.12ms/step - num_episode: 5 - avg_reward: 9.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 45/50\n10000/10000 [====================] - 42.59s 4.16ms/step - num_episode: 5 - avg_reward: 9.80\nPeak cuda memory used: 2263.87MB\n\nEpoch 46/50\n10000/10000 [====================] - 42.83s 4.18ms/step - num_episode: 5 - avg_reward: 9.00\nPeak cuda memory used: 2263.87MB\n\nEpoch 47/50\n10000/10000 [====================] - 42.59s 4.16ms/step - num_episode: 5 - avg_reward: 8.60\nPeak cuda memory used: 2263.87MB\n\nEpoch 48/50\n10000/10000 [====================] - 41.99s 4.10ms/step - num_episode: 5 - avg_reward: 9.40\nPeak cuda memory used: 2263.87MB\n\nEpoch 49/50\n10000/10000 [====================] - 42.80s 4.18ms/step - num_episode: 5 - avg_reward: 9.60\nPeak cuda memory used: 2263.87MB\n\nEpoch 50/50\n10000/10000 [====================] - 42.26s 4.12ms/step - num_episode: 5 - avg_reward: 9.00\nPeak cuda memory used: 2263.87MB\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\n\nwith open('baseline_rewards.pickle', 'wb') as handle:\n    pickle.dump(all_epoch_rewards, handle, protocol=pickle.HIGHEST_PROTOCOL)","metadata":{"execution":{"iopub.status.busy":"2023-06-01T19:49:11.014229Z","iopub.execute_input":"2023-06-01T19:49:11.014677Z","iopub.status.idle":"2023-06-01T19:49:11.020525Z","shell.execute_reply.started":"2023-06-01T19:49:11.014645Z","shell.execute_reply":"2023-06-01T19:49:11.019668Z"},"trusted":true},"execution_count":5,"outputs":[]}]}